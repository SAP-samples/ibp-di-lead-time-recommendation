{
	"properties": {},
	"description": "IBP Dynamic Lead Time Prediction - IBP LT Write IBP",
	"processes": {
		"artifactconsumer1": {
			"component": "com.sap.ml.artifact.consumer.v2",
			"metadata": {
				"label": "Get Prediction File Reference",
				"x": 336.99999809265137,
				"y": 40,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {}
			}
		},
		"python3operator1": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "Prepare Lead Time Data for IBP Write",
				"x": 1016.9999942779541,
				"y": 40,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "import pickle\nimport pandas as pd\n\ndef onIn(data):\n    df = pickle.loads(data)\n    df = df.drop([\"MONTH\", \"WEEKNUMBER\", \"WEEKDAY\", \"QTY\"], axis = 1)\n    df = df.rename({\"LOCID\" : \"LOCFR\"}, axis = 1)\n    df = df.rename({\"LOCTO\" : \"LOCID\"}, axis = 1)\n    df['DAY'] = df['DAY'].dt.strftime(\"%Y-%m-%dT00:00:00\")\n    df = df.rename({\"DAY\" : \"PERIODID0_TSTAMP\"}, axis = 1)\n    df[\"PREDICTEDLEADTIMES\"] = df[\"PREDICTEDLEADTIMES\"].round(2).clip(lower=0.01)\n    df = df.astype({\"PREDICTEDLEADTIMES\" : \"str\"})\n    api.send(\"out\", str(df.to_json()))\n\napi.set_port_callback(\"in\", onIn)"
				},
				"additionalinports": [
					{
						"name": "in",
						"type": "blob"
					}
				],
				"additionaloutports": [
					{
						"name": "out",
						"type": "string"
					}
				]
			}
		},
		"submitmetrics1": {
			"component": "com.sap.ml.submitMetrics",
			"metadata": {
				"label": "Submit Metrics",
				"x": 1541.9999914169312,
				"y": 40,
				"height": 80,
				"width": 120,
				"extensible": false,
				"config": {}
			}
		},
		"constantgenerator1": {
			"component": "com.sap.util.constantGenerator",
			"metadata": {
				"label": "Prediction File Name",
				"x": 17,
				"y": 32,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"content": "{\"artifact\": {\"id\": \"${ARTIFACT:PREDICTIONS}\"}}"
				}
			}
		},
		"tomessageconverter1": {
			"component": "com.sap.util.toMessageConverter",
			"metadata": {
				"label": "ToMessage Converter",
				"x": 201.99999904632568,
				"y": 47,
				"height": 50,
				"width": 50,
				"config": {}
			}
		},
		"tofile1": {
			"component": "com.sap.file.toFile",
			"metadata": {
				"label": "To File",
				"x": 597.9999961853027,
				"y": 47,
				"height": 50,
				"width": 50,
				"config": {}
			}
		},
		"toblobconverter1": {
			"component": "com.sap.util.toBlobConverter",
			"metadata": {
				"label": "ToBlob Converter",
				"x": 881.9999952316284,
				"y": 47,
				"height": 50,
				"width": 50,
				"config": {}
			}
		},
		"readfile1": {
			"component": "com.sap.file.read",
			"metadata": {
				"label": "Read Prediction File",
				"x": 696.9999961853027,
				"y": 32,
				"height": 80,
				"width": 120,
				"config": {}
			}
		},
		"graphterminator1": {
			"component": "com.sap.util.graphTerminator",
			"metadata": {
				"label": "Graph Terminator",
				"x": 1746.9999904632568,
				"y": 32,
				"height": 80,
				"width": 120,
				"config": {}
			}
		},
		"tomessageconverter2": {
			"component": "com.sap.util.toMessageConverter",
			"metadata": {
				"label": "ToMessage Converter",
				"x": 1406.9999923706055,
				"y": 47,
				"height": 50,
				"width": 50,
				"config": {}
			}
		},
		"pythonwriteibp1": {
			"component": "Python Write IBP",
			"metadata": {
				"label": "Write Lead Times to IBP",
				"x": 1221.9999933242798,
				"y": 32,
				"height": 80,
				"width": 120,
				"extensible": true,
				"generation": 1,
				"config": {
					"planningArea": "DIHUBPA",
					"ODataConnection": {
						"configurationType": "Configuration Manager",
						"connectionid": "SAP_COM_0720_DI"
					},
					"batchSize": 1000,
					"script": "import json\r\nimport math\r\n\r\nimport requests\r\nimport pandas as pd\r\n\r\nsession = requests.Session()\r\n\r\ndef getTransactionID(url, planningArea, user, password):\r\n    fullUrl = url + \"/getTransactionID\"\r\n    param = {'P_EntityName' : planningArea}\r\n    header = {\"X-CSRF-Token\" : \"Fetch\"}\r\n    r = session.get(fullUrl, params = param, headers = header, auth=(user, password))\r\n    r.encoding = 'utf-8'\r\n    resIndex = r.text.find('TRANSACTIONID') + 31\r\n    id = r.text[r.text.find(\"<d:Value>\") + 9 : r.text.find(\"</d:Value>\")]\r\n    token = r.headers['X-CSRF-Token']\r\n    return id, token\r\n\r\ndef onInput(data):\r\n    global dataframe\r\n    conn = api.config.ODataConnection[\"connectionProperties\"]\r\n    url = conn[\"url\"]\r\n    planningArea = api.config.planningArea\r\n    batchSize = api.config.batchSize\r\n    user = conn[\"user\"]\r\n    password = conn[\"password\"]\r\n    transactionID, token = getTransactionID(url, planningArea, user, password)\r\n    \r\n    fullUrl = url + \"/\" + planningArea + \"Trans\"\r\n    header = {\"X-CSRF-Token\" : token,\r\n        \"Content-Type\" : \"application/json\"\r\n    }\r\n    dataframe = pd.read_json(data)\r\n    nav_name = \"Nav\" + planningArea\r\n    iterator = dataframe.itertuples(index=False)\r\n    counter = 0\r\n    for batch in range(0, math.ceil(len(dataframe.index)/batchSize)):\r\n        transactionID, token = getTransactionID(url, planningArea, user, password)\r\n        to_send = {\r\n            \"AggregationLevelFieldsString\": getAggregationFields(),\r\n            \"DoCommit\": True,\r\n            \"VersionID\" : \"__BASELINE\",\r\n            nav_name: [],\r\n            \"Transactionid\": transactionID\r\n        }\r\n        for row in iterator:\r\n            to_send[nav_name].append(getRowJSON(row))\r\n            if counter == batchSize - 1:\r\n                counter = 0\r\n                break\r\n            counter += 1\r\n        r = session.post(fullUrl, data = json.dumps(to_send), headers = header, auth=(user, password))\r\n        \r\n        #api.send(\"out\", json.dumps(to_send))\r\n        #api.send(\"out\", str(r.status_code))\r\n        #api.send(\"out\", str(r.text))\r\n    #api.send(\"out\", '{\"'+str(dataframe.loc[0,'PRDID'])+'\":\"'+str(dataframe.loc[0,'LT'])+'\"}')        \r\n    \r\n      \r\ndef getRowJSON(row): # Iterates through the columns of a specific row and constructs ODATA-appropriate JSON for that row\r\n    row_json = {}\r\n    for column_name, column_value in enumerate(row):\r\n        row_json[dataframe.columns.values[column_name]] = str(column_value) # Everything that is sent must be sent as a string\r\n    return row_json\r\n    \r\ndef getAggregationFields():\r\n    columns = dataframe.columns.values.tolist()\r\n    fields_string = \"\"\r\n    for name in columns:\r\n        fields_string += name + \",\"\r\n    fields_string = fields_string[0:-1] # Getting rid of last \", \"\r\n    return fields_string\r\napi.set_port_callback('in', onInput)"
				}
			}
		}
	},
	"groups": [
		{
			"name": "group2",
			"nodes": [
				"artifactconsumer1"
			],
			"metadata": {
				"description": "Group"
			}
		},
		{
			"name": "group1",
			"nodes": [
				"python3operator1"
			],
			"metadata": {
				"description": "Group"
			},
			"tags": {
				"pandas": "1.0.3"
			}
		},
		{
			"name": "group3",
			"nodes": [
				"submitmetrics1"
			],
			"metadata": {
				"description": "Group"
			}
		}
	],
	"connections": [
		{
			"metadata": {
				"points": "141,72 168.99999952316284,72 168.99999952316284,81 196.99999904632568,81"
			},
			"src": {
				"port": "out",
				"process": "constantgenerator1"
			},
			"tgt": {
				"port": "instring",
				"process": "tomessageconverter1"
			}
		},
		{
			"metadata": {
				"points": "255.99999904632568,72 283.9999985694885,72 283.9999985694885,80 331.99999809265137,80"
			},
			"src": {
				"port": "out",
				"process": "tomessageconverter1"
			},
			"tgt": {
				"port": "inArtifact",
				"process": "artifactconsumer1"
			}
		},
		{
			"metadata": {
				"points": "460.99999809265137,71 488.9999976158142,71 488.9999976158142,80 564.9999966621399,80 564.9999966621399,81 592.9999961853027,81"
			},
			"src": {
				"port": "outArtifact",
				"process": "artifactconsumer1"
			},
			"tgt": {
				"port": "in",
				"process": "tofile1"
			}
		},
		{
			"metadata": {
				"points": "935.9999952316284,72 963.9999947547913,72 963.9999947547913,80 1011.9999942779541,80"
			},
			"src": {
				"port": "outbytearray",
				"process": "toblobconverter1"
			},
			"tgt": {
				"port": "in",
				"process": "python3operator1"
			}
		},
		{
			"metadata": {
				"points": "820.9999961853027,63 848.9999957084656,63 848.9999957084656,72 876.9999952316284,72"
			},
			"src": {
				"port": "file",
				"process": "readfile1"
			},
			"tgt": {
				"port": "ininterface",
				"process": "toblobconverter1"
			}
		},
		{
			"metadata": {
				"points": "651.9999961853027,72 691.9999961853027,72"
			},
			"src": {
				"port": "file",
				"process": "tofile1"
			},
			"tgt": {
				"port": "ref",
				"process": "readfile1"
			}
		},
		{
			"metadata": {
				"points": "1665.9999914169312,80 1713.999990940094,80 1713.999990940094,72 1741.9999904632568,72"
			},
			"src": {
				"port": "response",
				"process": "submitmetrics1"
			},
			"tgt": {
				"port": "stop",
				"process": "graphterminator1"
			}
		},
		{
			"metadata": {
				"points": "1460.9999923706055,72 1488.9999918937683,72 1488.9999918937683,80 1536.9999914169312,80"
			},
			"src": {
				"port": "out",
				"process": "tomessageconverter2"
			},
			"tgt": {
				"port": "metrics",
				"process": "submitmetrics1"
			}
		},
		{
			"metadata": {
				"points": "1140.999994277954,80 1188.999993801117,80 1188.999993801117,72 1216.9999933242798,72"
			},
			"src": {
				"port": "out",
				"process": "python3operator1"
			},
			"tgt": {
				"port": "in",
				"process": "pythonwriteibp1"
			}
		},
		{
			"metadata": {
				"points": "1345.9999933242798,72 1373.9999928474426,72 1373.9999928474426,63 1401.9999923706055,63"
			},
			"src": {
				"port": "out",
				"process": "pythonwriteibp1"
			},
			"tgt": {
				"port": "inbody",
				"process": "tomessageconverter2"
			}
		}
	],
	"inports": {},
	"outports": {},
	"metadata": {}
}